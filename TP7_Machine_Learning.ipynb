{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBY1Vdsp00eN"
   },
   "source": [
    "<center><h1> Série de Travaux Pratiques N° 7 - Machine Learning </h1></center>\n",
    "<center><h2> K-Nearest Neighbor and Decision Tree</h2></center>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OT_v-xSH8NW"
   },
   "source": [
    "Pour ce TP, on utilisera le **dataset IRIS**. Ce dernier est une base de données regroupant les caractéristiques de **trois espèces de fleurs d’Iris, à savoir Setosa, Versicolour et Virginica**. Chaque ligne de ce jeu de données est une observation des caractéristiques d’une fleur d’Iris. Ce dataset décrit les espèces d’Iris par quatre propriétés : longueur et largeur de sépales ainsi que longueur et largeur de pétales. La base de données comporte 150 observations (50 observations par espèce)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xIqBKf-_MK9"
   },
   "source": [
    "# **Partie I : K-Nearest Neighbor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fG-mqDhouw_G"
   },
   "source": [
    "# **Questions :**\n",
    "\n",
    "1- Importer les packages nécessaires\n",
    "\n",
    "2- Lire l'ensemble de données dans le dataframe pandas\n",
    "\n",
    "3- Afficher et explorer l'ensemble de données \"**iris.csv**\"\n",
    "\n",
    "4- Extraire les variables d'entrée X\n",
    "\n",
    "5- Extraire les variables de sortie y\n",
    "\n",
    "6- Diviser le dataset en Train / Test\n",
    "\n",
    "7- Mise à l'échelle des fonctionnalités avec Transform()\n",
    "\n",
    "8- Définir votre modèle **KNN**\n",
    "\n",
    "9- Entraîner le modèle\n",
    "\n",
    "10- Prédiction sur l'ensemble de test\n",
    "\n",
    "11- Évaluation du modèle à l'aide de métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ab1P8GZVw4gj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal.length  sepal.width  petal.length  petal.width variety\n",
      "0           5.1          3.5           1.4          0.2  Setosa\n",
      "1           4.9          3.0           1.4          0.2  Setosa\n",
      "2           4.7          3.2           1.3          0.2  Setosa\n",
      "3           4.6          3.1           1.5          0.2  Setosa\n",
      "4           5.0          3.6           1.4          0.2  Setosa\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal.length  150 non-null    float64\n",
      " 1   sepal.width   150 non-null    float64\n",
      " 2   petal.length  150 non-null    float64\n",
      " 3   petal.width   150 non-null    float64\n",
      " 4   variety       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n",
      "       sepal.length  sepal.width  petal.length  petal.width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.057333      3.758000     1.199333\n",
      "std        0.828066     0.435866      1.765298     0.762238\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n",
      "[[11  0  0]\n",
      " [ 0  7  0]\n",
      " [ 0  1 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Setosa       1.00      1.00      1.00        11\n",
      "  Versicolor       0.88      1.00      0.93         7\n",
      "   Virginica       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.96      0.97      0.96        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "96.66666666666667\n",
      "[[11  0  0]\n",
      " [ 0  7  0]\n",
      " [ 0  0 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Setosa       1.00      1.00      1.00        11\n",
      "  Versicolor       1.00      1.00      1.00         7\n",
      "   Virginica       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "# 1- Importer les packages nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 2- Lire l'ensemble de données dans le dataframe pandas\n",
    "data = pd.read_csv(\"iris.csv\")\n",
    "\n",
    "# 3- Afficher et explorer l'ensemble de données \"**iris.csv**\"\n",
    "# Afficher les premières lignes de l'ensemble de données\n",
    "print(data.head())\n",
    "\n",
    "# Afficher des informations sur l'ensemble de données\n",
    "print(data.info())\n",
    "\n",
    "# Afficher la description statistique de l'ensemble de données\n",
    "print(data.describe())\n",
    "\n",
    "# 4- Extraire les variables d'entrée X\n",
    "X = data.iloc[:, :-1].values\n",
    "\n",
    "# 5- Extraire les variables de sortie y\n",
    "Y = data.iloc[:, -1].values\n",
    "\n",
    "# 6- Diviser le dataset en Train / Test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 7- Mise à l'échelle des fonctionnalités avec StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Transformer les étiquettes de chaînes en entiers\n",
    "label_encoder = LabelEncoder()\n",
    "Y_train = label_encoder.fit_transform(Y_train)\n",
    "Y_test = label_encoder.transform(Y_test)\n",
    "\n",
    "# 8- Définir votre modèle KNN\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# 9- Entraîner le modèle\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "# 10- Prédiction sur l'ensemble de test\n",
    "Y_pred = classifier.predict(X_test)\n",
    "\n",
    "# 11- Évaluation du modèle à l'aide de métriques\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "print(f\"Accuracy: {accuracy_score(Y_test, Y_pred) * 100:.2f}%\")\n",
    "\n",
    "# 12- Changer le K = {5, 10, 20, 30, 40}, que remarquez-vous?\n",
    "for k in [10, 20, 30, 40]:\n",
    "    classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    Y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    print(f\"\\nK = {k}\")\n",
    "    print(confusion_matrix(Y_test, Y_pred))\n",
    "    print(classification_report(Y_test, Y_pred))\n",
    "    print(f\"Accuracy: {accuracy_score(Y_test, Y_pred) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRAn-qhBwqgp"
   },
   "source": [
    "# **Partie II : Decision Trees**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UU1ELn91wg2R"
   },
   "source": [
    "# **Questions :**\n",
    "\n",
    "1- Importer les packages nécessaires\n",
    "\n",
    "2- Lire l'ensemble de données dans le dataframe pandas\n",
    "\n",
    "3- Afficher et explorer l'ensemble de données \"**iris.csv**\"\n",
    "\n",
    "4- Extraire les variables d'entrée X\n",
    "\n",
    "5- Extraire les variables de sortie y\n",
    "\n",
    "6- Diviser le dataset en Train / Test\n",
    "\n",
    "7- Mise à l'échelle des fonctionnalités avec Transform()\n",
    "\n",
    "8- Définir votre modèle **Decision Tree**\n",
    "\n",
    "9- Entraîner le modèle\n",
    "\n",
    "10- Prédiction sur l'ensemble de test\n",
    "\n",
    "11- Évaluation du modèle à l'aide de métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "EfkJv-sMxI-c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal.length  sepal.width  petal.length  petal.width variety\n",
      "0           5.1          3.5           1.4          0.2  Setosa\n",
      "1           4.9          3.0           1.4          0.2  Setosa\n",
      "2           4.7          3.2           1.3          0.2  Setosa\n",
      "3           4.6          3.1           1.5          0.2  Setosa\n",
      "4           5.0          3.6           1.4          0.2  Setosa\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal.length  150 non-null    float64\n",
      " 1   sepal.width   150 non-null    float64\n",
      " 2   petal.length  150 non-null    float64\n",
      " 3   petal.width   150 non-null    float64\n",
      " 4   variety       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n",
      "       sepal.length  sepal.width  petal.length  petal.width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.057333      3.758000     1.199333\n",
      "std        0.828066     0.435866      1.765298     0.762238\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n",
      "[[14  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  1  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Setosa       1.00      1.00      1.00        14\n",
      "  Versicolor       0.91      1.00      0.95        10\n",
      "   Virginica       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.94      0.95        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "96.66666666666667\n"
     ]
    }
   ],
   "source": [
    "# IRIS Dataset : Decision Tree\n",
    "\n",
    "\n",
    "# 1- Importer les packages nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.datasets import make_classification  \n",
    "from sklearn.linear_model import SGDClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 2- Lire l'ensemble de données dans le dataframe pandas\n",
    "data=pd.read_csv(\"iris.csv\")\n",
    "# 3- Afficher et explorer l'ensemble de données \"iris.csv\"\n",
    "  # Afficher les premières lignes de l'ensemble de données\n",
    "print(data.head())\n",
    "\n",
    "  # Afficher des informations sur l'ensemble de données\n",
    "print(data.info())\n",
    "\n",
    "  # Afficher la description statistique de l'ensemble de données\n",
    "print(data.describe())\n",
    "# 4- Extraire les variables d'entrée X\n",
    "X=data.iloc[:, :-1].values\n",
    "X\n",
    "# 5- Extraire les variables de sortie y\n",
    "Y=data.iloc[:, -1].values\n",
    "Y\n",
    "# 6- Diviser le dataset en Train / Test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "# 7- Mise à l'échelle des fonctionnalités avec Transform()\n",
    "  # Créer un encodeur de labels\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "  # Transformer les étiquettes de chaînes en entiers\n",
    "Y = label_encoder.fit_transform(Y)\n",
    "# 8- Définir votre modèle KNN\n",
    "decision_tree_medel = DecisionTreeClassifier()\n",
    "# 9- Entraîner le modèle\n",
    "decision_tree_medel.fit(X_train, Y_train)\n",
    "# 10- Prédiction sur l'ensemble de test\n",
    "Y_pred= classifier.predict(X_test)\n",
    "# 11- Évaluation du modèle à l'aide de métriques\n",
    "print (confusion_matrix(Y_test,Y_pred))\n",
    "print (classification_report(Y_test,Y_pred))\n",
    "print (accuracy_score(Y_test,Y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
