{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBY1Vdsp00eN"
   },
   "source": [
    "<center><h1> Corréction Série de Travaux Pratiques N° 6 - Machine Learning </h1></center>\n",
    "<center><h2> Regression Logistique</h2></center>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xIqBKf-_MK9"
   },
   "source": [
    "# **Partie I : Regression Logistique**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OT_v-xSH8NW"
   },
   "source": [
    "Vous trouverez ci-joint un exemple d'utilisation d'algorithme de regréssion logistique avec les quatres étapes principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JhmrQYpLAkeD"
   },
   "outputs": [],
   "source": [
    "# Step 1: Import packages, functions\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Step 2: Get data\n",
    "x = np.arange(10).reshape(-1, 1)\n",
    "y = np.array([0, 1, 0, 0, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "# Step 3: Create a model and train it\n",
    "model = LogisticRegression(solver='liblinear', C=10.0, random_state=0, max_iter=100)\n",
    "model.fit(x, y)\n",
    "\n",
    "# Step 4: Evaluate the model\n",
    "p_pred = model.predict_proba(x)\n",
    "y_pred = model.predict(x)\n",
    "score_ = model.score(x, y)\n",
    "conf_m = confusion_matrix(y, y_pred)\n",
    "report = classification_report(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jl6j49CVBPZy",
    "outputId": "1fbd1535-bc83-4900-ad7d-5282b5b93143"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [7]\n",
      " [8]\n",
      " [9]]\n",
      "y: [0 1 0 0 1 1 1 1 1 1]\n",
      "intercept: [-1.51632619]\n",
      "coef: [[0.703457]]\n",
      "p_pred: [[0.81999686 0.18000314]\n",
      " [0.69272057 0.30727943]\n",
      " [0.52732579 0.47267421]\n",
      " [0.35570732 0.64429268]\n",
      " [0.21458576 0.78541424]\n",
      " [0.11910229 0.88089771]\n",
      " [0.06271329 0.93728671]\n",
      " [0.03205032 0.96794968]\n",
      " [0.0161218  0.9838782 ]\n",
      " [0.00804372 0.99195628]]\n",
      "y_pred: [0 0 0 1 1 1 1 1 1 1]\n",
      "score_: 0.8\n",
      "conf_m: [[2 1]\n",
      " [1 6]]\n",
      "report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         3\n",
      "           1       0.86      0.86      0.86         7\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.76      0.76      0.76        10\n",
      "weighted avg       0.80      0.80      0.80        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('x:', x)\n",
    "print('y:', y)\n",
    "print('intercept:', model.intercept_)\n",
    "print('coef:', model.coef_)\n",
    "print('p_pred:', p_pred)\n",
    "print('y_pred:', y_pred)\n",
    "print('score_:', score_)\n",
    "print('conf_m:', conf_m)\n",
    "print('report:', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CRPgzmJAP9p"
   },
   "source": [
    "# **Partie II : Classification Binaire**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifx0Fkf3QfMe"
   },
   "source": [
    "L'objectif de l'ensemble de données \"**diabetes.csv**\" est de prédire, sur la base de mesures diagnostiques, si un patient **souffre de diabète ou pas**.\n",
    "\n",
    "Ce dataset contient les caractéristiques suivants\n",
    "\n",
    "**Grossesses**: Nombre de fois enceintes.\n",
    "\n",
    "**Glucose**: concentration plasmatique de glucose à 2 heures lors d'un test oral de tolérance au glucose.\n",
    "\n",
    "**Pression artérielle** : tension artérielle diastolique (mm Hg).\n",
    "\n",
    "**Épaisseur de la peau** : épaisseur du pli cutané du triceps (mm).\n",
    "\n",
    "**Insuline** : insuline sérique de 2 heures (mu U/ml).\n",
    "\n",
    "**IMC** : Indice de masse corporelle (poids en kg/(taille en m)^2).\n",
    "\n",
    "**DiabetesPedigreeFunction** : fonction généalogique du diabète.\n",
    "\n",
    "**Âge** : Âge (ans).\n",
    "\n",
    "**Résultat** : variable de classe (0 ou 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFizXutMLhX1"
   },
   "source": [
    "### **Questions :**\n",
    "\n",
    "Étape 1 : Importer et afficher et explorer l'ensemble de données \"**diabetes.csv**\"\n",
    "\n",
    "Étape 2 : Créer dépendante d'une variable indépendante et stockée sur les variables X et Y.\n",
    "\n",
    "Étape 3 : Transformer les chaînes en entier.\n",
    "\n",
    "Étape 4 : Divisez les données en ensembles d'entrainement et de test.\n",
    "\n",
    "Étape 5 : Définir l'algorithme de régression logistique.\n",
    "\n",
    "Étape 6 :Tester les données de test en utilisant votre modèle.\n",
    "\n",
    "Étape 7 : Évaluation du modèle.\n",
    "\n",
    "Étape 8 : Prédire avec de nouvelles valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4wlRBxy0D99y",
    "outputId": "cefe284a-c332-46d5-8dd8-cb6ab624d608"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# # Se connecter\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O0NC3rVjEMTt",
    "outputId": "c99b0f4b-e00b-4002-b048-7794de9c3307"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks\n"
     ]
    }
   ],
   "source": [
    "cd drive/My Drive/Colab Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_NuxG5qDTWyp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n"
     ]
    }
   ],
   "source": [
    "# Binary Classification : Diabetes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.datasets import make_classification  \n",
    "from sklearn.linear_model import SGDClassifier \n",
    "\n",
    "\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      1\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "763    0\n",
       "764    0\n",
       "765    0\n",
       "766    1\n",
       "767    0\n",
       "Name: Outcome, Length: 768, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variables indépendantes (features)\n",
    "X = data.drop('Outcome', axis=1)\n",
    "X\n",
    "# Variable dépendante (target)\n",
    "Y = data['Outcome']\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Définir l'algorithme de régression logistique\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédire les valeurs sur l'ensemble de test\n",
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle : 74.68%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Classe 0       0.81      0.79      0.80        99\n",
      "    Classe 1       0.64      0.67      0.65        55\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.73      0.73       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Calculer la précision du modèle\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f\"Précision du modèle : {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "target_names = ['Classe 0', 'Classe 1']\n",
    "print(classification_report(Y_test, Y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédiction pour les nouvelles valeurs: [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Exemple de nouvelles valeurs (doivent être de la même forme que X)\n",
    "new_data = [[2, 150, 70, 35, 0, 33.6, 0.627, 50]]  # Remplacer par les nouvelles valeurs\n",
    "\n",
    "# Prédire avec le modèle entraîné\n",
    "new_prediction = model.predict(new_data)\n",
    "\n",
    "print(f\"Prédiction pour les nouvelles valeurs: {new_prediction}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3Zbjz_AAZ5l"
   },
   "source": [
    "# **Partie III : Classification Multi-Classe**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1NijNx4OpVg"
   },
   "source": [
    "Pour cette partie, on utilisera le **dataset IRIS**. Ce dernier est une base de données regroupant les caractéristiques de **trois espèces de fleurs d’Iris, à savoir Setosa, Versicolour et Virginica**. Chaque ligne de ce jeu de données est une observation des caractéristiques d’une fleur d’Iris. Ce dataset décrit les espèces d’Iris par quatre propriétés : longueur et largeur de sépales ainsi que longueur et largeur de pétales. La base de données comporte 150 observations (50 observations par espèce)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSTbiW8UMiPt"
   },
   "source": [
    "### **Questions :**\n",
    "\n",
    "Étape 1 : Importer, afficher et explorer l'ensemble de données \"**iris.csv**\"\n",
    "\n",
    "Étape 2 : Créer dépendante d'une variable indépendante et stockée sur les variables X et Y.\n",
    "\n",
    "Étape 3 : Transformer les chaînes en entier.\n",
    "\n",
    "Étape 4 : Divisez les données en ensembles d'entrainement et de test.\n",
    "\n",
    "Étape 5 : Définir l'algorithme de régression logistique.\n",
    "\n",
    "Étape 6 :Tester les données de test en utilisant votre modèle.\n",
    "\n",
    "Étape 7 : Évaluation du modèle.\n",
    "\n",
    "Étape 8 : Prédire avec de nouvelles valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "P8PUWA4oTlBB"
   },
   "outputs": [],
   "source": [
    "# Multi-Class Classification : IRIS Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal.length  sepal.width  petal.length  petal.width variety\n",
      "0           5.1          3.5           1.4          0.2  Setosa\n",
      "1           4.9          3.0           1.4          0.2  Setosa\n",
      "2           4.7          3.2           1.3          0.2  Setosa\n",
      "3           4.6          3.1           1.5          0.2  Setosa\n",
      "4           5.0          3.6           1.4          0.2  Setosa\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal.length  150 non-null    float64\n",
      " 1   sepal.width   150 non-null    float64\n",
      " 2   petal.length  150 non-null    float64\n",
      " 3   petal.width   150 non-null    float64\n",
      " 4   variety       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n",
      "       sepal.length  sepal.width  petal.length  petal.width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.057333      3.758000     1.199333\n",
      "std        0.828066     0.435866      1.765298     0.762238\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n"
     ]
    }
   ],
   "source": [
    "# Charger l'ensemble de données iris\n",
    "iris_data = pd.read_csv(\"iris.csv\")\n",
    "\n",
    "# Afficher les premières lignes de l'ensemble de données\n",
    "print(iris_data.head())\n",
    "\n",
    "# Afficher des informations sur l'ensemble de données\n",
    "print(iris_data.info())\n",
    "\n",
    "# Afficher la description statistique de l'ensemble de données\n",
    "print(iris_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa',\n",
       "       'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa',\n",
       "       'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa',\n",
       "       'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa',\n",
       "       'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa',\n",
       "       'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa',\n",
       "       'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa',\n",
       "       'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa', 'Setosa',\n",
       "       'Setosa', 'Setosa', 'Versicolor', 'Versicolor', 'Versicolor',\n",
       "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
       "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
       "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
       "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
       "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
       "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
       "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
       "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
       "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
       "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
       "       'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor',\n",
       "       'Versicolor', 'Versicolor', 'Versicolor', 'Virginica', 'Virginica',\n",
       "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
       "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
       "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
       "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
       "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
       "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
       "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
       "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
       "       'Virginica', 'Virginica', 'Virginica', 'Virginica', 'Virginica',\n",
       "       'Virginica', 'Virginica', 'Virginica'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supposons que les caractéristiques sont toutes les colonnes sauf la dernière\n",
    "X = iris_data.iloc[:, :-1].values\n",
    "X\n",
    "# Supposons que l'étiquette est la dernière colonne\n",
    "Y = iris_data.iloc[:, -1].values\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Créer un encodeur de labels\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Transformer les étiquettes de chaînes en entiers\n",
    "Y = label_encoder.fit_transform(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les données en ensembles d'entraînement et de test (80% entraînement, 20% test)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le modèle de régression logistique\n",
    "model = LogisticRegression(max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner le modèle avec les données d'entraînement\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Prédire les étiquettes pour les données de test\n",
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision du modèle : 100.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Setosa       1.00      1.00      1.00        10\n",
      "  Versicolor       1.00      1.00      1.00         9\n",
      "   Virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculer la précision du modèle\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f\"Précision du modèle : {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Afficher le rapport de classification\n",
    "print(classification_report(Y_test, Y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouvelles prédictions :  ['Setosa' 'Virginica']\n"
     ]
    }
   ],
   "source": [
    "# Exemple de nouvelles valeurs à prédire\n",
    "new_values = np.array([[5.1, 3.5, 1.4, 0.2], [6.7, 3.0, 5.2, 2.3]])\n",
    "\n",
    "# Prédire les étiquettes pour les nouvelles valeurs\n",
    "new_predictions = model.predict(new_values)\n",
    "\n",
    "# Convertir les prédictions en étiquettes originales\n",
    "new_predictions_labels = label_encoder.inverse_transform(new_predictions)\n",
    "\n",
    "print(\"Nouvelles prédictions : \", new_predictions_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
